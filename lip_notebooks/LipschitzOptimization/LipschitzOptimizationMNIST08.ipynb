{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "import keras.ops as K\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "\n",
    "# from keras.models import Sequential\n",
    "from deel.lip.model import Sequential\n",
    "\n",
    "from deel.lip.layers import (\n",
    "    SpectralDense,\n",
    "    SpectralConv2D,\n",
    "    ScaledL2NormPooling2D,\n",
    "    FrobeniusDense,\n",
    ")\n",
    "from deel.lip.activations import GroupSort, GroupSort2\n",
    "from deel.lip.losses import HKR, KR, HingeMargin, MulticlassHKR, MulticlassKR\n",
    "\n",
    "import numpy as np\n",
    "import decomon\n",
    "\n",
    "from data_processing import load_data, select_data_for_radius_evaluation_MNIST08\n",
    "from radius_evaluation_tools import compute_binary_certificate, starting_point_dichotomy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, y_test_ord = load_data(\"MNIST08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aws_install/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/aws_install/robustess_project/lip_models/demo3_FC_vanilla_MNIST08_channelfirst_False_disj_Neurons_single_output.keras\"\n",
    "model = keras.models.load_model(model_path)\n",
    "model.compile(\n",
    "   \n",
    "    loss=HKR(\n",
    "        alpha=10.0, min_margin=1.0\n",
    "    ),  # HKR stands for the hinge regularized KR loss\n",
    "    metrics=[\n",
    "        # KR,  # shows the KR term of the loss\n",
    "        HingeMargin(min_margin=1.0),  # shows the hinge term of the loss\n",
    "    ],\n",
    "    optimizer=Adam(learning_rate=0.001),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aws_install/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_bis = keras.models.load_model(\"/home/aws_install/robustess_project/lip_models/demo3_FC_vanilla_MNIST08_channelfirst_False_disj_Neurons_single_output_converted_4logits.keras\")\n",
    "model_bis.compile(\n",
    "        # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "        # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "        loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "        optimizer=Adam(1e-4),\n",
    "        metrics=[\"accuracy\", MulticlassKR()],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, idx_list = select_data_for_radius_evaluation_MNIST08(x_test, y_test_ord, model_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting/Generating Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5725006639080936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipschitz_decomon_tools import get_local_maximum, echantillonner_boule_l2_simple, square_backward_bounds, function_to_optimize_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_choosen = 55\n",
    "x = images[pt_choosen:pt_choosen+1].flatten().detach().cpu().numpy()\n",
    "label = labels[pt_choosen:pt_choosen+1]\n",
    "eps=0.5\n",
    "nb_pts = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate nb_pts random points within the ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06370150924629762\n",
      "0.4514828456636468\n",
      "0.03849168362062583\n",
      "0.21818509481831644\n",
      "0.09248876890841125\n",
      "0.46502662886661633\n",
      "0.1854948136066631\n",
      "0.18653074939382672\n",
      "0.25169979962137257\n",
      "0.4168406969150333\n"
     ]
    }
   ],
   "source": [
    "y_list = []\n",
    "for i in range(nb_pts):\n",
    "    ech = echantillonner_boule_l2_simple(x, eps)\n",
    "    print(np.linalg.norm(x-ech))\n",
    "    y_list.append(ech)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We solve our problem with these 10 random points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_adv, f_adv = get_local_maximum(x, label, eps, y_list, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.673187277227058"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from radius_evaluation_tools import single_compute_relaxation_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_working = single_compute_relaxation_radius(pt_choosen, images, labels, model, nb_pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_list = [x]\n",
    "# f_list = [get_local_maximum(x, label, eps, y_list, model)[1]]\n",
    "# for i in range(10):\n",
    "#     print(i)\n",
    "#     i = 2*i\n",
    "#     nb_pts = i+1\n",
    "#     y_list.append(echantillonner_boule_l2_simple(x, eps))\n",
    "#     x_adv, f_adv = get_local_maximum(x, label, eps, y_list, model)\n",
    "#     f_list.append(f_adv)\n",
    "\n",
    "# list_i = []\n",
    "# for i in range(3):\n",
    "#     list_i.append(2*i)\n",
    "\n",
    "\n",
    "# plt.scatter(list_i, f_list)\n",
    "# plt.xlabel(\"nb yi\")\n",
    "# plt.ylabel(\"max function\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3454614151835286\n",
      "[195.98196976]\n",
      "[196.19583053]\n",
      "[195.98540864]\n",
      "[195.88200628]\n",
      "[195.94679058]\n",
      "[195.86485926]\n",
      "[195.79642287]\n",
      "[196.13448578]\n",
      "[196.02867958]\n",
      "[196.00767629]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.681619765090458"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ech = echantillonner_boule_l2_simple(x, eps)\n",
    "print(np.linalg.norm(x-x_ech))\n",
    "x_ball_center = np.asarray(x, dtype=np.float64)\n",
    "\n",
    "l = x-eps\n",
    "u = x+eps\n",
    "\n",
    "W_list = []\n",
    "b_list = []\n",
    "for y_i in y_list:\n",
    "    # W, b = square_backward_bounds(l,u,y_i)\n",
    "    W, b = square_backward_bounds(l,u,y_i)\n",
    "    print(b)\n",
    "    W_list.append(W)\n",
    "    b_list.append(b)\n",
    "    \n",
    "function_to_optimize_all(x_ech, label, W_list, b_list, y_list, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyiavski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = []\n",
    "y_list.append(x)\n",
    "\n",
    "for i in range(20):\n",
    "    x_adv, f_adv = get_local_maximum(x, label, eps, y_list, model)\n",
    "    y_list.append(x_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.89740562438965"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(W_list[5] - W_list[1] != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_backward_bounds_reduced(l, u, y):\n",
    "    # l (4,)\n",
    "    # u (4,)\n",
    "    # y (4,)\n",
    "    l = l[151:153]\n",
    "    u = u[151:153]\n",
    "    y = y[151:153]\n",
    "    print(l, u, y)\n",
    "    u = u - y\n",
    "    l = l - y\n",
    "    print(u, l)\n",
    "\n",
    "    W = u + l #(4,)\n",
    "    print(W)\n",
    "    b = np.sum(-u*l) - W@y #scalar\n",
    "    # pdb.set_trace()\n",
    "    return W, np.array(b)[None]#(4,) & (1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = x-eps\n",
    "idx = np.nonzero(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([145, 146, 147, 148, 173, 174, 175, 176, 177, 182, 183, 184, 185,\n",
       "        186, 202, 203, 204, 205, 206, 210, 211, 212, 213, 214, 215, 216,\n",
       "        217, 230, 231, 232, 233, 234, 238, 239, 240, 241, 242, 243, 244,\n",
       "        245, 246, 260, 261, 262, 263, 264, 268, 269, 270, 271, 272, 273,\n",
       "        274, 289, 290, 291, 292, 293, 299, 300, 301, 302, 318, 319, 320,\n",
       "        321, 322, 326, 327, 328, 329, 330, 346, 347, 348, 349, 350, 353,\n",
       "        354, 355, 356, 357, 375, 376, 377, 378, 379, 380, 381, 382, 383,\n",
       "        384, 385, 404, 405, 406, 407, 408, 409, 410, 411, 412, 432, 433,\n",
       "        434, 435, 436, 437, 438, 458, 459, 460, 461, 462, 463, 464, 465,\n",
       "        466, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 513, 514,\n",
       "        515, 516, 517, 519, 520, 521, 522, 541, 542, 543, 544, 545, 548,\n",
       "        549, 550, 569, 570, 571, 572, 576, 577, 578, 579, 597, 598, 599,\n",
       "        600, 604, 605, 606, 607, 625, 626, 627, 628, 629, 630, 631, 632,\n",
       "        633, 634, 635, 654, 655, 656, 657, 658, 659, 660, 661, 662, 683,\n",
       "        684, 685, 686, 687, 688, 689, 690]),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63515117, 0.98249315])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_list[5][145: 147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63529414, 0.99215686], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[145: 147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5 -0.5] [0.5 0.5] [0.00628395 0.00533263]\n",
      "[0.49371605 0.49466737] [-0.50628395 -0.50533263]\n",
      "[-0.0125679  -0.01066527]\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = square_backward_bounds_reduced(x-eps, x+eps, y_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5 -0.5] [0.5 0.5] [0.00628395 0.00533263]\n",
      "[0.49371605 0.49466737] [-0.50628395 -0.50533263]\n",
      "[-0.0125679  -0.01066527]\n"
     ]
    }
   ],
   "source": [
    "W3, b3 = square_backward_bounds_reduced(np.asarray(x, dtype=np.float32)-eps, np.asarray(x, dtype=np.float32)+eps, y_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5 -0.5] [0.5 0.5] [-0.00148758 -0.01061017]\n",
      "[0.50148758 0.51061017] [-0.49851242 -0.48938983]\n",
      "[0.00297516 0.02122035]\n"
     ]
    }
   ],
   "source": [
    "W2, b2 = square_backward_bounds_reduced(np.asarray(x, dtype=np.float64)-eps, np.asarray(x, dtype=np.float64)+eps, y_list[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01725835, -0.00543194])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01725835, -0.00543194])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ech = echantillonner_boule_l2_simple(x, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'function' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunction_to_optimize_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ech\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mW1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb2\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m151\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m153\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/robustess_project/lip_notebooks/lipschitz_decomon_tools.py:25\u001b[0m, in \u001b[0;36mfunction_to_optimize_all\u001b[0;34m(x, label, W_list, b_list, y_list, model, L)\u001b[0m\n\u001b[1;32m     23\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     24\u001b[0m         function \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(outputs)    \n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'function' referenced before assignment"
     ]
    }
   ],
   "source": [
    "function_to_optimize_all(x_ech, label, [W1, W2], [b1, b2], y_list[151:153], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in range(len(y_list)):\n",
    "    output = model(y_list[i].reshape((1,28,28))[None]).cpu().detach().numpy()[0,0] +\\\n",
    "                1*np.sqrt(W_list[i]@x+b_list[i]) #scalar\n",
    "    outputs.append(output)\n",
    "function = np.min(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.681383384238005"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test comparison function without relaxation vs lip certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pts = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_choosen = 1\n",
    "# eps = np.abs(model(images[pt_choosen:pt_choosen+1]).detach().cpu().numpy())\n",
    "eps = 3.4\n",
    "x = images[pt_choosen:pt_choosen+1].flatten().detach().cpu().numpy()\n",
    "label = labels[pt_choosen:pt_choosen+1]\n",
    "\n",
    "y_list = []\n",
    "for i in range(nb_pts):\n",
    "    ech = echantillonner_boule_l2_simple(x, eps)\n",
    "    # print(np.linalg.norm(x-ech))\n",
    "    y_list.append(ech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_bar(z):\n",
    "    outputs = []\n",
    "    for i in range(len(y_list)):\n",
    "        output = model(y_list[i].reshape((1,28,28))[None]).cpu().detach().numpy()[0,0] +\\\n",
    "                    1*np.sqrt(np.sum(np.square(z - y_list[i]))) #scalar\n",
    "        outputs.append(output)\n",
    "    function = np.min(outputs)\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max([f_bar(echantillonner_boule_l2_simple(x, eps, uniform=False)) for _ in range(100)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour nb point donné quel est le rayon empirique obtenu : faire meme tableau que slides"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k3torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

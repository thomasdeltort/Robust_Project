{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pessimistic and Optimistic Bound on the Robustness Radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we try to study the different bounds of the robustness radius given by several methods (lip certificate, adv attacks, CROWN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from deel.lip.layers import (\n",
    "    SpectralDense,\n",
    "    SpectralConv2D,\n",
    "    ScaledL2NormPooling2D,\n",
    "    FrobeniusDense,\n",
    ")\n",
    "from deel.lip.model import Sequential\n",
    "from deel.lip.activations import GroupSort\n",
    "from deel.lip.losses import MulticlassHKR, MulticlassKR\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import keras.ops as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_pickle(\"/home/aws_install/robustess_project/lip_notebooks/data/Radius_Data/Radius_FMNIST.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Label_GT</th>\n",
       "      <th>Predicted_Label</th>\n",
       "      <th>Lipschitz_Constant</th>\n",
       "      <th>Robust_Epsilon</th>\n",
       "      <th>Adv_Epsilon_AA</th>\n",
       "      <th>Adv_Epsilon_PGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30577415</td>\n",
       "      <td>1.4137657</td>\n",
       "      <td>1.7910519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06562792</td>\n",
       "      <td>0.31114691</td>\n",
       "      <td>0.43479022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3217299</td>\n",
       "      <td>1.6402177</td>\n",
       "      <td>1.9918573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.041682042</td>\n",
       "      <td>0.2284363</td>\n",
       "      <td>0.38707727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5669894</td>\n",
       "      <td>2.728335</td>\n",
       "      <td>3.3219976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index Label_GT  Predicted_Label  Lipschitz_Constant Robust_Epsilon  \\\n",
       "5      6        0                0                 1.0     0.30577415   \n",
       "6      7        0                0                 1.0     0.06562792   \n",
       "7      8        0                0                 1.0      0.3217299   \n",
       "8      9        0                0                 1.0    0.041682042   \n",
       "9     10        0                0                 1.0      0.5669894   \n",
       "\n",
       "  Adv_Epsilon_AA Adv_Epsilon_PGD  \n",
       "5      1.4137657       1.7910519  \n",
       "6     0.31114691      0.43479022  \n",
       "7      1.6402177       1.9918573  \n",
       "8      0.2284363      0.38707727  \n",
       "9       2.728335       3.3219976  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Fashion MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the dataset has ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train_ord), (x_test, y_test_ord) = fashion_mnist.load_data()\n",
    "# standardize and reshape the data\n",
    "x_train = np.expand_dims(x_train, -1) / 255\n",
    "x_test = np.expand_dims(x_test, -1) / 255\n",
    "# one hot encode the labels\n",
    "y_train = to_categorical(y_train_ord)\n",
    "y_test = to_categorical(y_test_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.transpose(x_train,(0,3,1,2))\n",
    "x_test = np.transpose(x_test,(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"/home/aws_install/robustess_project/deel-lip/docs/notebooks/demo4_vanilla_fashionMNIST_channelfirst.keras\")\n",
    "# model.compile(\n",
    "#     # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "#     # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "#     loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "#     optimizer=Adam(1e-4),\n",
    "#     metrics=[\"accuracy\", MulticlassKR()],)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hkr_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"hkr_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ spectral_conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ScaledL2NormPooling2D</span>)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ScaledL2NormPooling2D</span>)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ spectral_conv2d (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mScaledL2NormPooling2D\u001b[0m)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mScaledL2NormPooling2D\u001b[0m)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m100,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vanilla_model = keras.models.load_model(\"/home/aws_install/robustess_project/lip_models/demo4_vanilla_fashionMNIST_channelfirst_False_disj_Neurons.keras\")\n",
    "vanilla_model.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],)\n",
    "vanilla_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# strategy: first\n",
    "# we select a sample from each class.\n",
    "images_list = []\n",
    "labels_list = []\n",
    "idx_list = []\n",
    "# select only a few element from the test set\n",
    "# selected = np.random.choice(len(y_test_ord), 500)\n",
    "sub_y_test_ord = y_test_ord[:400]\n",
    "sub_x_test = x_test[:400]\n",
    "# drop misclassified elements\n",
    "misclassified_mask = K.equal(\n",
    "    K.argmax(vanilla_model.predict(sub_x_test), axis=-1), sub_y_test_ord\n",
    ")\n",
    "misclassified_mask = misclassified_mask.detach().cpu().numpy()\n",
    "\n",
    "idx_global = np.arange(len(sub_x_test))[misclassified_mask]\n",
    "sub_x_test = sub_x_test[misclassified_mask]\n",
    "sub_y_test_ord = sub_y_test_ord[misclassified_mask]\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    # select the 20 firsts elements of the ith label\n",
    "    label_mask = sub_y_test_ord == i\n",
    "    x = sub_x_test[label_mask][:20]\n",
    "    y = sub_y_test_ord[label_mask][:20]\n",
    "    idx = idx_global[label_mask][:20]\n",
    "\n",
    "    # convert it to tensor for use with foolbox\n",
    "    images = K.convert_to_tensor(x.astype(\"float32\"), dtype=\"float32\")\n",
    "    labels = K.convert_to_tensor(y, dtype=\"int64\")\n",
    "    # repeat the input 10 times, one per misclassification target\n",
    "    for j in range(20):\n",
    "        images_list.append(images[j])\n",
    "        labels_list.append(labels[j])\n",
    "        idx_list.append(idx[j])\n",
    "images = K.convert_to_tensor(images_list)\n",
    "labels = K.convert_to_tensor(labels_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images shape = (nombre classes, nbr de points , channels, dim img 1, dim img 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Pessimistic Radius via Lip Constraints (l2 norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_certificate(images, model, L=1):    \n",
    "    values, _ = K.top_k(model(images), k=2)\n",
    "    certificates = (values[:, 0] - values[:, 1]) / (np.sqrt(2)*L)\n",
    "    return certificates.detach().cpu().numpy()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_radius = compute_certificate(images, vanilla_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3496229 , 0.13969153, 0.1685597 , 0.18583024, 0.3157398 ,\n",
       "       0.30577415, 0.06562792, 0.3217299 , 0.04168204, 0.5669894 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lip_radius[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Optimistic Radius via AutoAttacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aws_install/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras.ops as K\n",
    "import matplotlib.pyplot as plt\n",
    "import torchattacks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchattacks\n",
    "from robustbench.utils import clean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starting_point_dichotomy(idx, images, targets):\n",
    "    mask_different_classes = targets[idx] != targets\n",
    "    images_diffferent_classes = images[mask_different_classes]\n",
    "    return K.amin((images[idx] - images_diffferent_classes).square().sum(dim=(1, 2, 3)).sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8500, device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_point_dichotomy(1, images, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_compute_optimistic_radius_PGD(idx, images, targets, certificates, model, n_iter = 10):\n",
    "    image = images[idx:idx+1]\n",
    "    target = targets[idx:idx+1]\n",
    "    certificate = certificates[idx:idx+1]\n",
    "    # We use dichotomy algorithm to fine the smallest optimistic radius\n",
    "    # We start from the closest point with different class\n",
    "    eps_working = d_up = starting_point_dichotomy(1, images, targets)\n",
    "    d_low = K.convert_to_tensor(certificate)\n",
    "    for _ in range(n_iter):\n",
    "        print(eps_working)\n",
    "        eps_current = (d_up+d_low)/2\n",
    "        # atk_van = torchattacks.PGDL2(model, eps=eps_current, alpha=eps_current/5, steps=10, random_start=True)\n",
    "        atk_van = torchattacks.PGDL2(model, eps=eps_current, alpha=eps_current/5, steps=int((10*eps_current)), random_start=True)\n",
    "        adv_image = atk_van(image, target)\n",
    "        # return 0 if the attack doesn't work\n",
    "        if (K.argmax(model(adv_image), axis=1) == target):\n",
    "            d_low = eps_current\n",
    "        else:\n",
    "            eps_working = d_up = (image - adv_image).square().sum(dim=(1, 2, 3)).sqrt()\n",
    "    return eps_working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_compute_optimistic_radius_AA(idx, images, targets, certificates, model, n_iter = 10):\n",
    "    image = images[idx:idx+1]\n",
    "    target = targets[idx:idx+1]\n",
    "    certificate = certificates[idx:idx+1]\n",
    "    # We use dichotomy algorithm to fine the smallest optimistic radius\n",
    "    # We start from the closest point with different class\n",
    "    eps_working = d_up = starting_point_dichotomy(1, images, targets)\n",
    "    d_low = d_low = K.convert_to_tensor(certificate)\n",
    "    for _ in range(n_iter):\n",
    "        print(eps_working)\n",
    "        eps_current = (d_up+d_low)/2\n",
    "        atk = torchattacks.AutoAttack(model, norm='L2', eps=eps_current)\n",
    "        adv_image = atk(image, target)\n",
    "        if (K.argmax(model(adv_image), axis=1) == target):\n",
    "            d_low = eps_current\n",
    "        else:\n",
    "            eps_working = d_up = (image - adv_image).square().sum(dim=(1, 2, 3)).sqrt()\n",
    "    return eps_working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "eps_current = 1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8500, device='cuda:0')\n",
      "tensor([2.5952], device='cuda:0')\n",
      "tensor([2.5952], device='cuda:0')\n",
      "tensor([2.0312], device='cuda:0')\n",
      "tensor([2.0312], device='cuda:0')\n",
      "tensor([1.8895], device='cuda:0')\n",
      "tensor([1.8895], device='cuda:0')\n",
      "tensor([1.8531], device='cuda:0')\n",
      "tensor([1.8531], device='cuda:0')\n",
      "tensor([1.8531], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.8531], device='cuda:0')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_compute_optimistic_radius_PGD(i, images, labels, lip_radius, vanilla_model, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.8500, device='cuda:0')\n",
      "tensor([2.5669], device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor([2.5669], device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor([1.9756], device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor([1.7046], device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor([1.5707], device='cuda:0', grad_fn=<SqrtBackward0>)\n",
      "tensor([1.5707], device='cuda:0', grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msingle_compute_optimistic_radius_AA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlip_radius\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvanilla_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[91], line 13\u001b[0m, in \u001b[0;36msingle_compute_optimistic_radius_AA\u001b[0;34m(idx, images, targets, certificates, model, n_iter)\u001b[0m\n\u001b[1;32m     11\u001b[0m eps_current \u001b[38;5;241m=\u001b[39m (d_up\u001b[38;5;241m+\u001b[39md_low)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     12\u001b[0m atk \u001b[38;5;241m=\u001b[39m torchattacks\u001b[38;5;241m.\u001b[39mAutoAttack(model, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m'\u001b[39m, eps\u001b[38;5;241m=\u001b[39meps_current)\n\u001b[0;32m---> 13\u001b[0m adv_image \u001b[38;5;241m=\u001b[39m \u001b[43matk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (K\u001b[38;5;241m.\u001b[39margmax(model(adv_image), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m target):\n\u001b[1;32m     15\u001b[0m     d_low \u001b[38;5;241m=\u001b[39m eps_current\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/autoattack.py:199\u001b[0m, in \u001b[0;36mAutoAttack.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m    197\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    198\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 199\u001b[0m adv_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autoattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adv_images\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/wrappers/multiattack.py:55\u001b[0m, in \u001b[0;36mMultiAttack.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     52\u001b[0m multi_atk_records \u001b[38;5;241m=\u001b[39m [batch_size]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, attack \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattacks):\n\u001b[0;32m---> 55\u001b[0m     adv_images \u001b[38;5;241m=\u001b[39m \u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfails\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfails\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_logits(adv_images)\n\u001b[1;32m     58\u001b[0m     _, pre \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:79\u001b[0m, in \u001b[0;36mSquare.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     77\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     78\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 79\u001b[0m adv_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adv_images\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:477\u001b[0m, in \u001b[0;36mSquare.perturb\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m x_to_fool \u001b[38;5;241m=\u001b[39m x[ind_to_fool]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    475\u001b[0m y_to_fool \u001b[38;5;241m=\u001b[39m y[ind_to_fool]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 477\u001b[0m _, adv_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_single_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_to_fool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_to_fool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m output_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_logits(adv_curr)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargeted:\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:351\u001b[0m, in \u001b[0;36mSquare.attack_single_run\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    348\u001b[0m norms_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlp_norm(delta_curr \u001b[38;5;241m*\u001b[39m mask_image)\n\u001b[1;32m    350\u001b[0m new_deltas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones([x_curr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], c, s, s])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 351\u001b[0m new_deltas \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, s, s) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_choice(\n\u001b[1;32m    352\u001b[0m     [x_curr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], c, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    353\u001b[0m )\n\u001b[1;32m    354\u001b[0m old_deltas \u001b[38;5;241m=\u001b[39m delta_curr[:, :, vh : vh \u001b[38;5;241m+\u001b[39m s, vw : vw \u001b[38;5;241m+\u001b[39m s] \u001b[38;5;241m/\u001b[39m (\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;241m1e-12\u001b[39m \u001b[38;5;241m+\u001b[39m norms_window_1\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m new_deltas \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m old_deltas\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:164\u001b[0m, in \u001b[0;36mSquare.eta\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21meta\u001b[39m(\u001b[38;5;28mself\u001b[39m, s):\n\u001b[1;32m    163\u001b[0m     delta \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros([s, s])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 164\u001b[0m     delta[: s \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meta_rectangles\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     delta[s \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m :] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_rectangles(s \u001b[38;5;241m-\u001b[39m s \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, s)\n\u001b[1;32m    166\u001b[0m     delta \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (delta \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msqrt()\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:153\u001b[0m, in \u001b[0;36mSquare.eta_rectangles\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    147\u001b[0m counter2 \u001b[38;5;241m=\u001b[39m [x_c \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, y_c \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m counter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m(x_c, y_c)):\n\u001b[1;32m    149\u001b[0m     delta[\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28mmax\u001b[39m(counter2[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m) : \u001b[38;5;28mmin\u001b[39m(counter2[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), x),\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, counter2[\u001b[38;5;241m1\u001b[39m]) : \u001b[38;5;28mmin\u001b[39m(counter2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m counter \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), y),\n\u001b[1;32m    152\u001b[0m     ] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcounter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    154\u001b[0m     )  \u001b[38;5;66;03m# nopep8\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     counter2[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    156\u001b[0m     counter2[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "single_compute_optimistic_radius_AA(i, images, labels, lip_radius, vanilla_model, n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3496229]\n"
     ]
    }
   ],
   "source": [
    "print(lip_radius[i:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.9000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "atk_van = torchattacks.PGDL2(vanilla_model, eps=eps_current, alpha=3*eps_current/256, steps=int((eps_current)*256), random_start=True)\n",
    "adv_image = atk_van(images[i:i+1], labels[i:i+1])\n",
    "print((images[i:i+1] - adv_image).square().sum(dim=(1, 2, 3)).sqrt() if (K.argmax(vanilla_model(adv_image), axis=1) != labels[i:i+1]) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.8979], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "atk_van = torchattacks.PGDL2(vanilla_model, eps=eps_current, alpha=eps_current/5, steps=int((10*eps_current)), random_start=True)\n",
    "adv_image = atk_van(images[i:i+1], labels[i:i+1])\n",
    "print((images[i:i+1] - adv_image).square().sum(dim=(1, 2, 3)).sqrt() if (K.argmax(vanilla_model(adv_image), axis=1) != labels[i:i+1]) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7852], device='cuda:0', grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "atk = torchattacks.AutoAttack(vanilla_model, norm='L2', eps=eps_current)\n",
    "adv_image = atk(images[i:i+1], labels[i:i+1])\n",
    "print((images[i:i+1] - adv_image).square().sum(dim=(1, 2, 3)).sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found an adversarial attack for eps= tensor([2.0949], device='cuda:0')\n",
      "Launching Dichotomy :\n",
      "0 1.0488687 False\n",
      "1 1.573303 False\n",
      "2 1.8355201 False\n",
      "3 1.9666288 True\n",
      "4 1.9010744 False\n",
      "5 1.9338516 False\n",
      "6 1.9502401 True\n",
      "7 1.9420459 True\n",
      "8 1.9379487 False\n",
      "9 1.9399973 True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float32(1.9399973)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_PGD = []\n",
    "eps_AA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m----> 2\u001b[0m     eps_AA\u001b[38;5;241m.\u001b[39mappend(\u001b[43msingle_compute_optimistic_radius_AA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlip_radius\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvanilla_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m, in \u001b[0;36msingle_compute_optimistic_radius_AA\u001b[0;34m(image, target, certificate, model, n_iter)\u001b[0m\n\u001b[1;32m      8\u001b[0m     eps_current \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m*\u001b[39mcertificate[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m     atk \u001b[38;5;241m=\u001b[39m torchattacks\u001b[38;5;241m.\u001b[39mAutoAttack(model, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m'\u001b[39m, eps\u001b[38;5;241m=\u001b[39meps_current)\n\u001b[0;32m---> 10\u001b[0m     adv_image \u001b[38;5;241m=\u001b[39m \u001b[43matk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     optimistic_radius \u001b[38;5;241m=\u001b[39m (image \u001b[38;5;241m-\u001b[39m adv_image)\u001b[38;5;241m.\u001b[39msquare()\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe found an adversarial attack for eps=\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m*\u001b[39mcertificate)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/autoattack.py:199\u001b[0m, in \u001b[0;36mAutoAttack.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m    197\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    198\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 199\u001b[0m adv_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autoattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adv_images\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/wrappers/multiattack.py:55\u001b[0m, in \u001b[0;36mMultiAttack.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     52\u001b[0m multi_atk_records \u001b[38;5;241m=\u001b[39m [batch_size]\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, attack \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattacks):\n\u001b[0;32m---> 55\u001b[0m     adv_images \u001b[38;5;241m=\u001b[39m \u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfails\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfails\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_logits(adv_images)\n\u001b[1;32m     58\u001b[0m     _, pre \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attack.py:511\u001b[0m, in \u001b[0;36mAttack.__call__\u001b[0;34m(self, inputs, labels, *args, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_normalization_applied(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m     adv_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;66;03m# adv_inputs = self.to_type(adv_inputs, self.return_type)\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recover_model_mode(given_training)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:79\u001b[0m, in \u001b[0;36mSquare.forward\u001b[0;34m(self, images, labels)\u001b[0m\n\u001b[1;32m     77\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     78\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 79\u001b[0m adv_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperturb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m adv_images\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:477\u001b[0m, in \u001b[0;36mSquare.perturb\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    474\u001b[0m x_to_fool \u001b[38;5;241m=\u001b[39m x[ind_to_fool]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    475\u001b[0m y_to_fool \u001b[38;5;241m=\u001b[39m y[ind_to_fool]\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 477\u001b[0m _, adv_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack_single_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_to_fool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_to_fool\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m output_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_logits(adv_curr)\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargeted:\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torchattacks/attacks/square.py:394\u001b[0m, in \u001b[0;36mSquare.attack_single_run\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    388\u001b[0m loss_min[idx_to_fool] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    389\u001b[0m     idx_improved \u001b[38;5;241m*\u001b[39m loss \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m idx_improved) \u001b[38;5;241m*\u001b[39m loss_min_curr\n\u001b[1;32m    390\u001b[0m )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# update margin and x_best if new loss is better\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# or misclassification\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m idx_miscl \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mmargin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m idx_improved \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(idx_improved, idx_miscl)\n\u001b[1;32m    397\u001b[0m margin_min[idx_to_fool] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    398\u001b[0m     idx_improved \u001b[38;5;241m*\u001b[39m margin \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m idx_improved) \u001b[38;5;241m*\u001b[39m margin_min_curr\n\u001b[1;32m    399\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(images.shape[0]):\n",
    "    eps_AA.append(single_compute_optimistic_radius_AA(images[i:i+1], labels[i:i+1], lip_radius[i:i+1], vanilla_model, n_iter = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found an adversarial attack for eps= [2.3915052]\n",
      "Launching Dichotomy :\n",
      "0 1.1957526 False\n",
      "1 1.7936289 False\n",
      "2 2.092567 True\n",
      "3 1.943098 False\n",
      "4 2.0178325 True\n",
      "5 1.9804652 False\n",
      "6 1.9991488 False\n",
      "7 2.0084906 False\n",
      "8 2.0131617 True\n",
      "9 2.010826 False\n",
      "10 2.011994 False\n",
      "11 2.0125778 False\n",
      "12 2.0128698 False\n",
      "13 2.0130157 True\n",
      "We found an adversarial attack for eps= [0.47378108]\n",
      "Launching Dichotomy :\n",
      "0 0.23689054 False\n",
      "1 0.3553358 False\n",
      "2 0.41455844 False\n",
      "3 0.44416976 False\n",
      "4 0.45897543 False\n",
      "5 0.46637827 True\n",
      "6 0.46267685 True\n",
      "7 0.46082616 False\n",
      "8 0.46175152 True\n",
      "9 0.46128884 True\n",
      "We found an adversarial attack for eps= [1.2187829]\n",
      "Launching Dichotomy :\n",
      "0 0.60939145 False\n",
      "1 0.9140872 False\n",
      "2 1.0664351 False\n",
      "3 1.142609 False\n",
      "4 1.180696 False\n",
      "5 1.1997395 True\n",
      "6 1.1902177 False\n",
      "7 1.1949786 True\n",
      "8 1.1925981 False\n",
      "9 1.1937883 True\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    eps_PGD.append(single_compute_optimistic_radius_PGD(images[i:i+1], labels[i:i+1], lip_radius[i:i+1], vanilla_model, n_iter = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(2.0130157), np.float32(0.46128884), np.float32(1.1937883)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps_AA = K.convert_to_tensor(eps_AA)\n",
    "eps_PGD = K.convert_to_tensor(eps_PGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "        8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "        9, 9, 9, 9, 9, 9, 9, 9], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print results\n",
    "# print(\"Image #     Certificate     Distance to adversarial\")\n",
    "# print(\"--------------------------------------------------------------------------------------------------------------\")\n",
    "# for i in range(10):\n",
    "#     print(f\"Image {i}        {lip_radius[i]:.3f}                {eps_AA[i]:.2f}                    {eps_PGD[i]:.2f}  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lip_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m total_points \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Création du DataFrame avec une colonne d'index de 1 à 200\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'Index': np.arange(1, total_points + 1),\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'Label_GT': labels.detach().cpu().numpy(),  \u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'Label_Predit': np.argmax(vanilla_model(images).detach().cpu().numpy(), axis=1),  \u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'Constante_Lipschitz': np.ones(total_points), \u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'Epsilon_Robuste': lip_radius,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 'Epsilon_Adv_AA': eps_AA,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEpsilon_Adv_PGD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_PGD\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Affichage des premières lignes du DataFrame\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/pandas/core/internals/construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/pandas/core/internals/construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[1;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[1;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/pandas/core/construction.py:630\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy:\n\u001b[0;32m--> 630\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/torch/_tensor.py:1194\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# penser à tout convertir en numpy\n",
    "total_points = images.shape[0]\n",
    "\n",
    "# Création du DataFrame avec une colonne d'index de 1 à 200\n",
    "df = pd.DataFrame({\n",
    "    # 'Index': np.arange(1, total_points + 1),\n",
    "    # 'Label_GT': labels.detach().cpu().numpy(),  \n",
    "    # 'Label_Predit': np.argmax(vanilla_model(images).detach().cpu().numpy(), axis=1),  \n",
    "    # 'Constante_Lipschitz': np.ones(total_points), \n",
    "    # 'Epsilon_Robuste': lip_radius,\n",
    "    # 'Epsilon_Adv_AA': eps_AA,\n",
    "    'Epsilon_Adv_PGD': eps_PGD\n",
    "})\n",
    "\n",
    "# Affichage des premières lignes du DataFrame\n",
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k3torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

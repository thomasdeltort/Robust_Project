{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "import keras.ops as K\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import BinaryAccuracy\n",
    "\n",
    "# from keras.models import Sequential\n",
    "from deel.lip.model import Sequential\n",
    "\n",
    "from deel.lip.layers import (\n",
    "    SpectralDense,\n",
    "    SpectralConv2D,\n",
    "    ScaledL2NormPooling2D,\n",
    "    FrobeniusDense,\n",
    ")\n",
    "from deel.lip.activations import GroupSort, GroupSort2\n",
    "from deel.lip.losses import HKR, KR, HingeMargin, MulticlassHKR, MulticlassKR\n",
    "\n",
    "import numpy as np\n",
    "import decomon\n",
    "\n",
    "from data_processing import load_data, select_data_for_radius_evaluation_MNIST08\n",
    "from radius_evaluation_tools import compute_binary_certificate, starting_point_dichotomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test, y_test_ord = load_data(\"MNIST08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aws_install/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 12 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/aws_install/robustess_project/lip_models/demo3_FC_vanilla_MNIST08_channelfirst_False_disj_Neurons_single_output.keras\"\n",
    "model = keras.models.load_model(model_path)\n",
    "model.compile(\n",
    "   \n",
    "    loss=HKR(\n",
    "        alpha=10.0, min_margin=1.0\n",
    "    ),  # HKR stands for the hinge regularized KR loss\n",
    "    metrics=[\n",
    "        # KR,  # shows the KR term of the loss\n",
    "        HingeMargin(min_margin=1.0),  # shows the hinge term of the loss\n",
    "    ],\n",
    "    optimizer=Adam(learning_rate=0.001),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aws_install/miniconda3/envs/k3torchenv/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 14 variables whereas the saved optimizer has 2 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "model_bis = keras.models.load_model(\"/home/aws_install/robustess_project/lip_models/demo3_FC_vanilla_MNIST08_channelfirst_False_disj_Neurons_single_output_converted_4logits.keras\")\n",
    "model_bis.compile(\n",
    "        # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "        # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "        loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "        optimizer=Adam(1e-4),\n",
    "        metrics=[\"accuracy\", MulticlassKR()],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, idx_list = select_data_for_radius_evaluation_MNIST08(x_test, y_test_ord, model_bis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5725006639080936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lipschitz_decomon_tools import get_local_maximum, echantillonner_boule_l2_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_choosen = 1\n",
    "x = images[pt_choosen:pt_choosen+1].flatten().detach().cpu().numpy()\n",
    "label = labels[pt_choosen:pt_choosen+1]\n",
    "eps=0.5\n",
    "nb_pts = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list = []\n",
    "for i in range(nb_pts):\n",
    "    y_list.append(echantillonner_boule_l2_simple(x, eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_adv, f_adv = get_local_maximum(x, label, eps, y_list, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radius_evaluation_tools import single_compute_relaxation_radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_working = single_compute_relaxation_radius(pt_choosen, images, labels, model, y_list, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k3torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deel.lip.layers import (\n",
    "    SpectralDense,\n",
    "    SpectralConv2D,\n",
    "    ScaledL2NormPooling2D,\n",
    "    FrobeniusDense,\n",
    ")\n",
    "\n",
    "from keras import Sequential\n",
    "# from deel.lip.model import Sequential\n",
    "from deel.lip.activations import GroupSort\n",
    "from deel.lip.losses import MulticlassHKR, MulticlassKR\n",
    "from keras.layers import Input, Flatten, Conv2D, Dense, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import to_categorical\n",
    "import keras.ops as K\n",
    "import numpy as np\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train, y_train_ord), (x_test, y_test_ord) = fashion_mnist.load_data()\n",
    "# standardize and reshape the data\n",
    "x_train = np.expand_dims(x_train, -1) / 255\n",
    "x_test = np.expand_dims(x_test, -1) / 255\n",
    "# one hot encode the labels\n",
    "y_train = to_categorical(y_train_ord)\n",
    "y_test = to_categorical(y_test_ord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class MyScaledL2NormPooling2D(keras.layers.AveragePooling2D):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pool_size=(2, 2),\n",
    "        strides=None,\n",
    "        padding=\"valid\",\n",
    "        data_format=None,\n",
    "        k_coef_lip=1.0,\n",
    "        eps_grad_sqrt=1e-6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if not ((strides == pool_size) or (strides is None)):\n",
    "            raise RuntimeError(\"stride must be equal to pool_size\")\n",
    "        if padding != \"valid\":\n",
    "            raise RuntimeError(\"ScaledL2NormPooling2D only supports padding='valid'\")\n",
    "        if eps_grad_sqrt < 0.0:\n",
    "            raise RuntimeError(\"eps_grad_sqrt must be positive\")\n",
    "        super(MyScaledL2NormPooling2D, self).__init__(\n",
    "            pool_size=pool_size,\n",
    "            strides=pool_size,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.built = False\n",
    "        # self.set_klip_factor(k_coef_lip)\n",
    "        self.eps_grad_sqrt = eps_grad_sqrt\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(MyScaledL2NormPooling2D, self).build(input_shape)\n",
    "        # self._init_lip_coef(input_shape)\n",
    "        self.built = True\n",
    "\n",
    "    def _compute_lip_coef(self, input_shape=None):\n",
    "        return np.sqrt(np.prod(np.asarray(self.pool_size)))\n",
    "\n",
    "    def call(self, x):\n",
    "        return K.sqrt(super().call(K.square(x)) + self.eps_grad_sqrt)*2\n",
    "    def get_config(self):\n",
    "        base_config = super(MyScaledL2NormPooling2D, self).get_config()\n",
    "        return dict(list(base_config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class GroupSort(Layer):\n",
    "    def __init__(self, n=None, data_format=\"channels_last\", k_coef_lip=1.0, **kwargs):\n",
    "        # self.set_klip_factor(k_coef_lip)\n",
    "        super(GroupSort, self).__init__(**kwargs)\n",
    "        if data_format == \"channels_last\":\n",
    "            self.channel_axis = -1\n",
    "        elif data_format == \"channels_first\":\n",
    "            raise RuntimeError(\n",
    "                \"channels_first not implemented for GroupSort activation\"\n",
    "            )\n",
    "        else:\n",
    "            raise RuntimeError(\"data format not understood\")\n",
    "        self.n = n\n",
    "        self.data_format = data_format\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(GroupSort, self).build(input_shape)\n",
    "        # self._init_lip_coef(input_shape)\n",
    "        if (self.n is None) or (self.n > input_shape[self.channel_axis]):\n",
    "            self.n = input_shape[self.channel_axis]\n",
    "        if (input_shape[self.channel_axis] % self.n) != 0:\n",
    "            raise RuntimeError(\"self.n has to be a divisor of the number of channels\")\n",
    "        input_shape = tuple(input_shape)\n",
    "        self.flat_shape = (\n",
    "            (-1,) + input_shape[1:-1] + (input_shape[-1] // self.n, self.n)\n",
    "        )\n",
    "        self.out_shape = (-1,) + input_shape[1:]\n",
    "\n",
    "    def _compute_lip_coef(self, input_shape=None):\n",
    "        return 1.0\n",
    "\n",
    "    def call(self, x):\n",
    "        fv = K.reshape(x, self.flat_shape)\n",
    "        if self.n == 2:\n",
    "            b, c = K.split(fv, 2, axis=-1)\n",
    "            newv = K.concatenate([K.minimum(b, c), K.maximum(b, c)], axis=-1)\n",
    "            newv = K.reshape(newv, self.out_shape)\n",
    "            return newv \n",
    "\n",
    "        newv = K.sort(fv)\n",
    "        newv = K.reshape(newv, self.out_shape)\n",
    "        return newv \n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"n\": self.n,\n",
    "            # \"k_coef_lip\": self.k_coef_lip,\n",
    "            \"data_format\": self.data_format,\n",
    "        }\n",
    "        base_config = super(GroupSort, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class GroupSort2(GroupSort):\n",
    "    def __init__(self, **kwargs):\n",
    "        kwargs[\"n\"] = 2\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hkr_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"hkr_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_scaled_l2_norm_pooling2d_3   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyScaledL2NormPooling2D</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_scaled_l2_norm_pooling2d_4   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MyScaledL2NormPooling2D</span>)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_6 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_scaled_l2_norm_pooling2d_3   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMyScaledL2NormPooling2D\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_7 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my_scaled_l2_norm_pooling2d_4   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMyScaledL2NormPooling2D\u001b[0m)       │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m100,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_8 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sequential (resp Model) from deel.model has the same properties as any lipschitz model.\n",
    "# It act only as a container, with features specific to lipschitz\n",
    "# functions (condensation, vanilla_exportation...)\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=x_train.shape[1:]),\n",
    "        # Lipschitz layers preserve the API of their superclass ( here Conv2D )\n",
    "        # an optional param is available: k_coef_lip which control the lipschitz\n",
    "        # constant of the layer\n",
    "        Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            # activation=orGroupSt(2),\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "            padding='same'\n",
    "        ),\n",
    "        GroupSort2(),\n",
    "        # usual pooling layer are implemented (avg, max...), but new layers are also available\n",
    "        MyScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "        Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            # activation=GroupSort(2),\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "            padding='same',\n",
    "        ),\n",
    "        GroupSort2(),\n",
    "        MyScaledL2NormPooling2D(pool_size=(2, 2), data_format=\"channels_last\"),\n",
    "        # our layers are fully interoperable with existing keras layers\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "            64,\n",
    "            # activation=GroupSort(2),\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "        ),\n",
    "        GroupSort2(),\n",
    "        Dense(\n",
    "            y_train.shape[-1],\n",
    "            activation=None,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "        ),\n",
    "    ],\n",
    "    # similary model has a parameter to set the lipschitz constant\n",
    "    # to set automatically the constant of each layer\n",
    "    name=\"hkr_model\",\n",
    ")\n",
    "\n",
    "# HKR (Hinge-Krantorovich-Rubinstein) optimize robustness along with accuracy\n",
    "model.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import LPPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class MyLPPool2D(Layer):\n",
    "    def __init__(self, pool_size=(2, 2), eps_grad_sqrt=1e-6):\n",
    "        super(MyLPPool2D, self).__init__()\n",
    "        \n",
    "        self.pool_size = pool_size\n",
    "        self.stride = pool_size  # Stride fixé à pool_size comme dans ta version Keras\n",
    "        self.eps_grad_sqrt = eps_grad_sqrt\n",
    "\n",
    "    def call(self, x):\n",
    "        x_squared = torch.square(x)  # Élève au carré (équivalent à K.square(x))\n",
    "        x_avg_pool = F.avg_pool2d(x_squared, kernel_size=self.pool_size, stride=self.stride, padding=0)  # Moyenne des valeurs au carré\n",
    "        x_out = torch.sqrt(x_avg_pool + self.eps_grad_sqrt)  # Ajoute eps_grad_sqrt et prend la racine carrée\n",
    "        return x_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@keras.saving.register_keras_serializable()\n",
    "class My2LPPool2D(keras.layers.AveragePooling2D):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pool_size=(2, 2),\n",
    "        strides=None,\n",
    "        padding=\"valid\",\n",
    "        data_format=None,\n",
    "        eps_grad_sqrt=1e-6,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if not ((strides == pool_size) or (strides is None)):\n",
    "            raise RuntimeError(\"stride must be equal to pool_size\")\n",
    "        if padding != \"valid\":\n",
    "            raise RuntimeError(\"ScaledL2NormPooling2D only supports padding='valid'\")\n",
    "        if eps_grad_sqrt < 0.0:\n",
    "            raise RuntimeError(\"eps_grad_sqrt must be positive\")\n",
    "        super(My2LPPool2D, self).__init__(\n",
    "            pool_size=pool_size,\n",
    "            strides=pool_size,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            **kwargs,\n",
    "        )\n",
    "        self.eps_grad_sqrt = eps_grad_sqrt\n",
    "        self._kwargs = kwargs\n",
    "    def call(self, x):\n",
    "        return K.sqrt(super().call(K.square(x))+ self.eps_grad_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hkr_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"hkr_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my2lp_pool2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">My2LPPool2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my2lp_pool2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">My2LPPool2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_3 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my2lp_pool2d (\u001b[38;5;33mMy2LPPool2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_4 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ my2lp_pool2d_1 (\u001b[38;5;33mMy2LPPool2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m100,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_5 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sequential (resp Model) from deel.model has the same properties as any lipschitz model.\n",
    "# It act only as a container, with features specific to lipschitz\n",
    "# functions (condensation, vanilla_exportation...)\n",
    "model = Sequential(\n",
    "    [\n",
    "        Input(shape=x_train.shape[1:]),\n",
    "        # Lipschitz layers preserve the API of their superclass ( here Conv2D )\n",
    "        # an optional param is available: k_coef_lip which control the lipschitz\n",
    "        # constant of the layer\n",
    "        Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=(3, 3),\n",
    "            # activation=orGroupSt(2),\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "            padding='same'\n",
    "        ),\n",
    "        GroupSort2(),\n",
    "        # usual pooling layer are implemented (avg, max...), but new layers are also available\n",
    "        My2LPPool2D(),\n",
    "        Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(3, 3),\n",
    "            # activation=GroupSort(2),\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "            padding='same',\n",
    "        ),\n",
    "        GroupSort2(),\n",
    "        My2LPPool2D(),\n",
    "        # our layers are fully interoperable with existing keras layers\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "            64,\n",
    "            # activation=GroupSort(2),\n",
    "            use_bias=True,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "        ),\n",
    "        GroupSort2(),\n",
    "        Dense(\n",
    "            y_train.shape[-1],\n",
    "            activation=None,\n",
    "            use_bias=False,\n",
    "            kernel_initializer=\"orthogonal\",\n",
    "        ),\n",
    "    ],\n",
    "    # similary model has a parameter to set the lipschitz constant\n",
    "    # to set automatically the constant of each layer\n",
    "    name=\"hkr_model\",\n",
    ")\n",
    "\n",
    "# HKR (Hinge-Krantorovich-Rubinstein) optimize robustness along with accuracy\n",
    "model.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = keras.saving.load_model(\"convdense_gs2_pool_fashionMNIST.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.45261514,  0.6381362 ,  0.04317522,  0.40430403, -1.2057297 ,\n",
       "        -0.71725094, -0.66472304, -0.01536794,  0.50754654, -0.5321394 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.predict(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"hkr_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"hkr_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ spectral_conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ScaledL2NormPooling2D</span>)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ScaledL2NormPooling2D</span>)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1568</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GroupSort2</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ frobenius_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ spectral_conv2d (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2 (\u001b[38;5;33mGroupSort2\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mScaledL2NormPooling2D\u001b[0m)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_1 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ scaled_l2_norm_pooling2d_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mScaledL2NormPooling2D\u001b[0m)         │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1568\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spectral_dense (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m100,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ group_sort2_2 (\u001b[38;5;33mGroupSort2\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ frobenius_dense (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">317,570</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m317,570\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">105,856</span> (413.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m105,856\u001b[0m (413.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">211,714</span> (827.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m211,714\u001b[0m (827.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(model_tf.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.4526153 ,  0.63813627,  0.04317522,  0.4043044 , -1.2057296 ,\n",
       "        -0.7172508 , -0.664723  , -0.0153679 ,  0.50754684, -0.5321399 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([[-0.45264804,  0.63833827,  0.04332048,  0.40417057, -1.2056267 ,\n",
    "        -0.7172017 , -0.6649481 , -0.01542646,  0.50755   , -0.53229195]],\n",
    "      dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "submodel = Sequential([MyScaledL2NormPooling2D()])\n",
    "submodel.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")\n",
    "pred1 = submodel.predict(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.0119335 ],\n",
       "         [0.00440212],\n",
       "         [0.02752374],\n",
       "         [0.14511183],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.00589554],\n",
       "         [0.00809412],\n",
       "         [0.7438407 ],\n",
       "         [0.43352866],\n",
       "         [0.002     ],\n",
       "         [0.08629769],\n",
       "         [0.7235933 ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.01765146],\n",
       "         [0.5776733 ],\n",
       "         [0.99460495],\n",
       "         [1.2935843 ],\n",
       "         [1.2730023 ],\n",
       "         [1.2139536 ],\n",
       "         [1.1853344 ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.00440212],\n",
       "         [0.00440212],\n",
       "         [0.00899408],\n",
       "         [0.01675759],\n",
       "         [0.34902534],\n",
       "         [0.9082666 ],\n",
       "         [0.97843146],\n",
       "         [1.1829578 ],\n",
       "         [1.2581042 ],\n",
       "         [1.2299684 ],\n",
       "         [1.2613516 ],\n",
       "         [0.19312523]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.01127074],\n",
       "         [0.00899408],\n",
       "         [0.01765146],\n",
       "         [0.00440212],\n",
       "         [0.43563423],\n",
       "         [0.8907251 ],\n",
       "         [0.87681276],\n",
       "         [1.1173117 ],\n",
       "         [1.1135685 ],\n",
       "         [1.2121027 ],\n",
       "         [1.2030096 ],\n",
       "         [1.23682   ],\n",
       "         [0.8396669 ]],\n",
       "\n",
       "        [[0.0119335 ],\n",
       "         [0.23018172],\n",
       "         [0.39218158],\n",
       "         [0.5762206 ],\n",
       "         [0.8111702 ],\n",
       "         [0.886485  ],\n",
       "         [0.9103384 ],\n",
       "         [1.0341591 ],\n",
       "         [1.1116127 ],\n",
       "         [1.2482992 ],\n",
       "         [1.2179818 ],\n",
       "         [1.1694317 ],\n",
       "         [1.2216758 ],\n",
       "         [1.0274156 ]],\n",
       "\n",
       "        [[0.7653116 ],\n",
       "         [0.82626307],\n",
       "         [0.8311622 ],\n",
       "         [0.8184931 ],\n",
       "         [0.8712792 ],\n",
       "         [0.9575477 ],\n",
       "         [0.9989326 ],\n",
       "         [1.0936345 ],\n",
       "         [1.217521  ],\n",
       "         [1.2990357 ],\n",
       "         [1.4145304 ],\n",
       "         [1.3238026 ],\n",
       "         [1.3819469 ],\n",
       "         [1.0877124 ]],\n",
       "\n",
       "        [[0.49808955],\n",
       "         [0.9977234 ],\n",
       "         [1.1428212 ],\n",
       "         [1.322745  ],\n",
       "         [1.3375152 ],\n",
       "         [1.3620114 ],\n",
       "         [1.4403707 ],\n",
       "         [1.3061254 ],\n",
       "         [1.290865  ],\n",
       "         [1.0740393 ],\n",
       "         [1.7470896 ],\n",
       "         [1.7182167 ],\n",
       "         [1.5716504 ],\n",
       "         [1.0208082 ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]]]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "submodel = Sequential([My2LPPool2D()])\n",
    "submodel.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")\n",
    "pred2 = submodel.predict(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.00596675],\n",
       "         [0.00220106],\n",
       "         [0.01376187],\n",
       "         [0.07255591],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.00294777],\n",
       "         [0.00404706],\n",
       "         [0.37192035],\n",
       "         [0.21676433],\n",
       "         [0.001     ],\n",
       "         [0.04314885],\n",
       "         [0.36179665],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.00882573],\n",
       "         [0.28883666],\n",
       "         [0.49730247],\n",
       "         [0.6467922 ],\n",
       "         [0.63650113],\n",
       "         [0.6069768 ],\n",
       "         [0.5926672 ],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.00220106],\n",
       "         [0.00220106],\n",
       "         [0.00449704],\n",
       "         [0.00837879],\n",
       "         [0.17451267],\n",
       "         [0.4541333 ],\n",
       "         [0.48921573],\n",
       "         [0.5914789 ],\n",
       "         [0.6290521 ],\n",
       "         [0.6149842 ],\n",
       "         [0.6306758 ],\n",
       "         [0.09656262]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.00563537],\n",
       "         [0.00449704],\n",
       "         [0.00882573],\n",
       "         [0.00220106],\n",
       "         [0.21781711],\n",
       "         [0.44536254],\n",
       "         [0.43840638],\n",
       "         [0.55865586],\n",
       "         [0.5567843 ],\n",
       "         [0.6060513 ],\n",
       "         [0.6015048 ],\n",
       "         [0.61841   ],\n",
       "         [0.41983345]],\n",
       "\n",
       "        [[0.00596675],\n",
       "         [0.11509086],\n",
       "         [0.19609079],\n",
       "         [0.2881103 ],\n",
       "         [0.4055851 ],\n",
       "         [0.4432425 ],\n",
       "         [0.4551692 ],\n",
       "         [0.51707953],\n",
       "         [0.55580634],\n",
       "         [0.6241496 ],\n",
       "         [0.6089909 ],\n",
       "         [0.58471584],\n",
       "         [0.6108379 ],\n",
       "         [0.5137078 ]],\n",
       "\n",
       "        [[0.3826558 ],\n",
       "         [0.41313154],\n",
       "         [0.4155811 ],\n",
       "         [0.40924656],\n",
       "         [0.4356396 ],\n",
       "         [0.47877386],\n",
       "         [0.4994663 ],\n",
       "         [0.54681724],\n",
       "         [0.6087605 ],\n",
       "         [0.64951783],\n",
       "         [0.7072652 ],\n",
       "         [0.6619013 ],\n",
       "         [0.69097346],\n",
       "         [0.5438562 ]],\n",
       "\n",
       "        [[0.24904478],\n",
       "         [0.4988617 ],\n",
       "         [0.5714106 ],\n",
       "         [0.6613725 ],\n",
       "         [0.6687576 ],\n",
       "         [0.6810057 ],\n",
       "         [0.72018534],\n",
       "         [0.6530627 ],\n",
       "         [0.6454325 ],\n",
       "         [0.53701967],\n",
       "         [0.8735448 ],\n",
       "         [0.8591083 ],\n",
       "         [0.7858252 ],\n",
       "         [0.5104041 ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ]],\n",
       "\n",
       "        [[0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ],\n",
       "         [0.001     ]]]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(np.abs(pred1-pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "submodel = keras.saving.load_model('toy.keras')\n",
    "submodel.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")\n",
    "pred3 = submodel.predict(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.0119335 ],\n",
       "         [0.00440212],\n",
       "         [0.02752374],\n",
       "         [0.14511183],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.00589554],\n",
       "         [0.00809412],\n",
       "         [0.7438407 ],\n",
       "         [0.43352866],\n",
       "         [0.002     ],\n",
       "         [0.08629769],\n",
       "         [0.7235933 ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.01765146],\n",
       "         [0.5776733 ],\n",
       "         [0.99460495],\n",
       "         [1.2935843 ],\n",
       "         [1.2730023 ],\n",
       "         [1.2139536 ],\n",
       "         [1.1853344 ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.00440212],\n",
       "         [0.00440212],\n",
       "         [0.00899408],\n",
       "         [0.01675759],\n",
       "         [0.34902534],\n",
       "         [0.9082666 ],\n",
       "         [0.97843146],\n",
       "         [1.1829578 ],\n",
       "         [1.2581042 ],\n",
       "         [1.2299684 ],\n",
       "         [1.2613516 ],\n",
       "         [0.19312523]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.01127074],\n",
       "         [0.00899408],\n",
       "         [0.01765146],\n",
       "         [0.00440212],\n",
       "         [0.43563423],\n",
       "         [0.8907251 ],\n",
       "         [0.87681276],\n",
       "         [1.1173117 ],\n",
       "         [1.1135685 ],\n",
       "         [1.2121027 ],\n",
       "         [1.2030096 ],\n",
       "         [1.23682   ],\n",
       "         [0.8396669 ]],\n",
       "\n",
       "        [[0.0119335 ],\n",
       "         [0.23018172],\n",
       "         [0.39218158],\n",
       "         [0.5762206 ],\n",
       "         [0.8111702 ],\n",
       "         [0.886485  ],\n",
       "         [0.9103384 ],\n",
       "         [1.0341591 ],\n",
       "         [1.1116127 ],\n",
       "         [1.2482992 ],\n",
       "         [1.2179818 ],\n",
       "         [1.1694317 ],\n",
       "         [1.2216758 ],\n",
       "         [1.0274156 ]],\n",
       "\n",
       "        [[0.7653116 ],\n",
       "         [0.82626307],\n",
       "         [0.8311622 ],\n",
       "         [0.8184931 ],\n",
       "         [0.8712792 ],\n",
       "         [0.9575477 ],\n",
       "         [0.9989326 ],\n",
       "         [1.0936345 ],\n",
       "         [1.217521  ],\n",
       "         [1.2990357 ],\n",
       "         [1.4145304 ],\n",
       "         [1.3238026 ],\n",
       "         [1.3819469 ],\n",
       "         [1.0877124 ]],\n",
       "\n",
       "        [[0.49808955],\n",
       "         [0.9977234 ],\n",
       "         [1.1428212 ],\n",
       "         [1.322745  ],\n",
       "         [1.3375152 ],\n",
       "         [1.3620114 ],\n",
       "         [1.4403707 ],\n",
       "         [1.3061254 ],\n",
       "         [1.290865  ],\n",
       "         [1.0740393 ],\n",
       "         [1.7470896 ],\n",
       "         [1.7182167 ],\n",
       "         [1.5716504 ],\n",
       "         [1.0208082 ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]]]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "submodel = keras.saving.load_model('toy2.keras')\n",
    "submodel.compile(\n",
    "    # decreasing alpha and increasing min_margin improve robustness (at the cost of accuracy)\n",
    "    # note also in the case of lipschitz networks, more robustness require more parameters.\n",
    "    loss=MulticlassHKR(alpha=100, min_margin=0.25),\n",
    "    optimizer=Adam(1e-4),\n",
    "    metrics=[\"accuracy\", MulticlassKR()],\n",
    ")\n",
    "pred4 = submodel.predict(x_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.0119335 ],\n",
       "         [0.00440212],\n",
       "         [0.02752374],\n",
       "         [0.14511183],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.00589554],\n",
       "         [0.00809412],\n",
       "         [0.7438407 ],\n",
       "         [0.43352866],\n",
       "         [0.002     ],\n",
       "         [0.08629769],\n",
       "         [0.7235933 ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.01765146],\n",
       "         [0.5776733 ],\n",
       "         [0.99460495],\n",
       "         [1.2935843 ],\n",
       "         [1.2730023 ],\n",
       "         [1.2139536 ],\n",
       "         [1.1853344 ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.00440212],\n",
       "         [0.00440212],\n",
       "         [0.00899408],\n",
       "         [0.01675759],\n",
       "         [0.34902534],\n",
       "         [0.9082666 ],\n",
       "         [0.97843146],\n",
       "         [1.1829578 ],\n",
       "         [1.2581042 ],\n",
       "         [1.2299684 ],\n",
       "         [1.2613516 ],\n",
       "         [0.19312523]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.01127074],\n",
       "         [0.00899408],\n",
       "         [0.01765146],\n",
       "         [0.00440212],\n",
       "         [0.43563423],\n",
       "         [0.8907251 ],\n",
       "         [0.87681276],\n",
       "         [1.1173117 ],\n",
       "         [1.1135685 ],\n",
       "         [1.2121027 ],\n",
       "         [1.2030096 ],\n",
       "         [1.23682   ],\n",
       "         [0.8396669 ]],\n",
       "\n",
       "        [[0.0119335 ],\n",
       "         [0.23018172],\n",
       "         [0.39218158],\n",
       "         [0.5762206 ],\n",
       "         [0.8111702 ],\n",
       "         [0.886485  ],\n",
       "         [0.9103384 ],\n",
       "         [1.0341591 ],\n",
       "         [1.1116127 ],\n",
       "         [1.2482992 ],\n",
       "         [1.2179818 ],\n",
       "         [1.1694317 ],\n",
       "         [1.2216758 ],\n",
       "         [1.0274156 ]],\n",
       "\n",
       "        [[0.7653116 ],\n",
       "         [0.82626307],\n",
       "         [0.8311622 ],\n",
       "         [0.8184931 ],\n",
       "         [0.8712792 ],\n",
       "         [0.9575477 ],\n",
       "         [0.9989326 ],\n",
       "         [1.0936345 ],\n",
       "         [1.217521  ],\n",
       "         [1.2990357 ],\n",
       "         [1.4145304 ],\n",
       "         [1.3238026 ],\n",
       "         [1.3819469 ],\n",
       "         [1.0877124 ]],\n",
       "\n",
       "        [[0.49808955],\n",
       "         [0.9977234 ],\n",
       "         [1.1428212 ],\n",
       "         [1.322745  ],\n",
       "         [1.3375152 ],\n",
       "         [1.3620114 ],\n",
       "         [1.4403707 ],\n",
       "         [1.3061254 ],\n",
       "         [1.290865  ],\n",
       "         [1.0740393 ],\n",
       "         [1.7470896 ],\n",
       "         [1.7182167 ],\n",
       "         [1.5716504 ],\n",
       "         [1.0208082 ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]],\n",
       "\n",
       "        [[0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ],\n",
       "         [0.002     ]]]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k3torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
